import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import explained_variance_score, max_error
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, VotingRegressor, StackingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
from sklearn.impute import SimpleImputer

# Load data from the local Excel file
df = pd.read_excel("Main_Data_Set.xlsx")

# Extract input and output data for the first 676 sets
X = df[['Nodes', 'Radius', 'packet_sent', 'Packet_received', 'Actual PDR']].iloc[:676]
Y = df[['SF7', 'SF8', 'SF9', 'SF10', 'SF11', 'SF12']].iloc[:676]  # Multiple outputs


# Impute missing values in the input data
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Handle missing values in the target variable Y
Y_imputed = np.nan_to_num(Y)

# Define models
models = {
    "Bagging": BaggingRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Voting": VotingRegressor([('lr', LinearRegression()), ('dt', DecisionTreeRegressor()), ('rf', RandomForestRegressor())]),
    "Stacking": StackingRegressor([('lr', LinearRegression()), ('dt', DecisionTreeRegressor()), ('rf', RandomForestRegressor())]),
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(),
    "k-Nearest Neighbors": KNeighborsRegressor(),
}

# Perform train-test split for the subset of data
X_train, X_test, Y_train, Y_test = train_test_split(X_imputed, Y_imputed, test_size=0.2, random_state=42)

# Scale input features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Aggregate predictions from all models and compute evaluation metrics
metrics = {}
for model_name, model in models.items():
    # Fit the model for each output column individually
    Y_train_pred = np.zeros_like(Y_train)
    Y_test_pred = np.zeros_like(Y_test)
    
    for i in range(Y_train.shape[1]):  # Iterate over each output column
        # Fit the model
        model.fit(X_train_scaled, Y_train[:, i])
        
        # Predict for train and test sets
        Y_train_pred[:, i] = model.predict(X_train_scaled)
        Y_test_pred[:, i] = model.predict(X_test_scaled)

    # Compute evaluation metrics
    mse = mean_squared_error(Y_test, Y_test_pred)
    mae = mean_absolute_error(Y_test, Y_test_pred)
    r2_train = r2_score(Y_train, Y_train_pred)
    r2_test = r2_score(Y_test, Y_test_pred)
    explained_variance = explained_variance_score(Y_test, Y_test_pred)
    max_err = np.max(np.abs(Y_test - Y_test_pred), axis=0)  # Maximum error for each output variable
    
    metrics[model_name] = {
        'MSE': mse,
        'MAE': mae,
        'R2 Train': r2_train,
        'R2 Test': r2_test,
        'Explained Variance': explained_variance,
        'Max Error': max_err
    }

# Print evaluation metrics for each model
for model_name, metrics_dict in metrics.items():
    print(f"Model: {model_name}")
    print(f"MSE: {metrics_dict['MSE']}")
    print(f"MAE: {metrics_dict['MAE']}")
    print(f"R2 Train: {metrics_dict['R2 Train']}")
    print(f"R2 Test: {metrics_dict['R2 Test']}")
    print(f"Explained Variance: {metrics_dict['Explained Variance']}")
    print(f"Max Error: {metrics_dict['Max Error']}")
    print()




